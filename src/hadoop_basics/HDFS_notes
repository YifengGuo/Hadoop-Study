HDFS vs HBase
    1. Similarities: can store and retrieve(query) data

    2. Differences:
            2.1 HBase is a database which is to store processed data (in some structure which is designed to
            make query more efficiently)

            2.2 HDFS is a filesystem, so it usually is to store raw data or data which do not need
                to be processed into some form

HDFS: A fault-tolerant distributed filesystem designed to run on inexpensive hardware (downward expansion)

Why HDFS:
        1. Faster than single machine
        2. Files are split into several data blocks
        3. Each data blocks are replicated into several replicas

                       mapping                         mapping
        DataNode  <--------------->   Data Blocks  <------------->   Files
                    <- replicated                     <- split
                       & store

Architecture of HDFS: Master-slave model

        request  HDFS Client --->    master
                                   /   |   \  schedule job respectively
                                  /    |    \
                               slave1  slave2 slave3

                 HDFS Client will divide files into blocks (neither master nor slaves)
                 e.g: the cmds the user input will be received by client and the client will handle the cmds
                 Users operate NameNode through Client

    1. Master slave model: machines do not communicate with each other, only receive and send info from and to master
        1.1 High consistency:
            1.1.1 only master can send orders
            1.1.2 master will monitor each slave and guarantee the operation has done successfully

        1.2 Simpler design

        1.3 Single master node is not robust

    2. Peer peer model
        2.1 Distributed read write load

        2.2 One node down will not affect the others

        2.3 Low consistency

    Master will not read / write data directly or it will become a bottleneck
    Master will decide which slave node to read/write, then client will do the
    operation to slave node because the volume of data is huge and master node
    should not handle this process

    The client do not have to write to three DataNodes or it will end up in bottleneck

    What do we store on master machine?
        1. Metadata:
            1.1 File blocks (files ----> divided into which blocks
                                   ----> where blocks are)


    What if one slave node fail?
        Data loss

    How to avoid data loss?
        Data replication

    What is master node fail?
        We have SecondaryNameNode

    How to write in HDFS?
        See images for details
            1. Client says I wanna write something
            2. Master check the available slaves and make determination which slaves to be written and tell the Client
            start to write
            3. Client tell the slaves to be ready and slaves send back ACK (slave by slave)
            4. Client start to write data and each slave sends received message to Master if the process succeeds
            5. Tips: if prefix slaves fails, the write process will not succeed
                    there is a in-memory data queue that store the data that is to-be-written, only every slave
                    is ready and send back ACK, the write process will begin


    ● Data is kept in different racks (physically separate machines). To ensure if one rack fails, we still
      have another rack to hold the data.
    ● Keep two blocks(slaves) in same rack to achieve high throughput while
      reading data because two machines in same rack have more
      bandwidth and lower latency.
    ● Client does not send blocks to all 3 data nodes identified by Name
      node. The reason is Client will be choked by data transmission at a
      time.
    ● Name Node creates metadata from block reports received from data
      nodes

    Read:
        Master is always preferred to read the data from the closest slave
        Blocks are sorted by master in certain order and split at the very beginning
        The slave nodes order are decided by the distance between slave
        node and the client.
        The closer, the faster.

    We knew that slaves cannot communicate with each other, how will the write process happen successfully?
        Slaves cannot communicate with each other by their own. The communication between slaves during write process
        are driven by NameNode

Why default replication factor of Hadoop is 3?
	Replication factor is the number of times Hadoop framework replicates each and every Data Block
	Block replication is designed to provide fault tolerance

	The reasons why 3:
		Fault Tolerance:
			1. If one copy is not accessible and corrupted then the data can be read from other copy.
			2. You will have ample time to send an alert to namenode and recover the duplication of the failed node into a new node.
			3. In meantime if the second node also failed unplanned, you will still have one active with your critical data to process.

		Rack Awareness:
			Replication factor 3 works properly in all situations without over replicating data and 
			replication less than 3 could be challenging at the time data recovery.